{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94231696",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Ki·ªÉm Tra GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7967c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"üîç Ki·ªÉm tra GPU...\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ Found {len(gpus)} GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   - {gpu.name}\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU found. Vui l√≤ng b·∫≠t GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803dfeb",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Dataset\n",
    "\n",
    "Upload 3 files CSV t·ª´ m√°y t√≠nh c·ªßa b·∫°n:\n",
    "- `XSS_dataset.csv`\n",
    "- `Modified_SQL_Dataset.csv`\n",
    "- `DDOS_dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9aa1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üì§ Upload c√°c file dataset...\")\n",
    "print(\"Ch·ªçn 3 files: XSS_dataset.csv, Modified_SQL_Dataset.csv, DDOS_dataset.csv\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\n‚úÖ Files uploaded:\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"   - {filename} ({len(uploaded[filename])} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8bcb8",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc80ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d3d8c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3888a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"MODEL_NAME\": \"MalwareDetection_Text_LSTM\",\n",
    "    \"MAX_TOKENS\": 10000,\n",
    "    \"SEQUENCE_LENGTH\": 200,\n",
    "    \"EMBEDDING_DIM\": 128,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"OUTPUT_DIR\": 'output'\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"OUTPUT_DIR\"], exist_ok=True)\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b200faf",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    print(\"\\nüìä Loading data...\")\n",
    "    \n",
    "    datasets = {\n",
    "        'XSS': 'XSS_dataset.csv',\n",
    "        'SQL': 'Modified_SQL_Dataset.csv',\n",
    "        'DDOS': 'DDOS_dataset.csv'\n",
    "    }\n",
    "    \n",
    "    df_list = []\n",
    "    for source, path in datasets.items():\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            df['source'] = source\n",
    "            df_list.append(df)\n",
    "            print(f\"‚úÖ Loaded {len(df):,} samples from {source}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Warning: {path} not found\")\n",
    "    \n",
    "    if not df_list:\n",
    "        print(\"‚ùå No datasets loaded\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Separate DDoS\n",
    "    df_ddos = df_all[df_all['source'] == 'DDOS'].copy()\n",
    "    df_non_ddos = df_all[df_all['source'] != 'DDOS'].copy()\n",
    "    \n",
    "    print(f\"\\nüìà DDoS samples: {len(df_ddos):,}\")\n",
    "    print(f\"üìà Non-DDoS samples: {len(df_non_ddos):,}\")\n",
    "    \n",
    "    df = df_non_ddos.copy()\n",
    "    df = df[df['Sentence'].str.strip().str.split().str.len() > 2]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total samples after filtering: {len(df):,}\")\n",
    "    print(f\"   - Positive (Malware): {len(df[df['Label']==1]):,}\")\n",
    "    print(f\"   - Negative (Benign): {len(df[df['Label']==0]):,}\")\n",
    "    \n",
    "    texts = df['Sentence'].fillna('').astype(str).values\n",
    "    labels = df['Label'].values\n",
    "    \n",
    "    # Split 70-15-15\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        texts, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n",
    "    \n",
    "    print(f\"\\nüìä Data Split:\")\n",
    "    print(f\"   - Train: {len(train_texts):,} samples (70%)\")\n",
    "    print(f\"   - Val: {len(val_texts):,} samples (15%)\")\n",
    "    print(f\"   - Test: {len(test_texts):,} samples (15%)\")\n",
    "    \n",
    "    # Text Vectorization\n",
    "    vectorize_layer = keras.layers.TextVectorization(\n",
    "        max_tokens=CONFIG[\"MAX_TOKENS\"],\n",
    "        output_mode='int',\n",
    "        output_sequence_length=CONFIG[\"SEQUENCE_LENGTH\"])\n",
    "    \n",
    "    vectorize_layer.adapt(train_texts)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_texts, train_labels))\n",
    "    train_ds = train_ds.shuffle(10000).batch(CONFIG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_texts, val_labels))\n",
    "    val_ds = val_ds.batch(CONFIG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_texts, test_labels))\n",
    "    test_ds = test_ds.batch(CONFIG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, vectorize_layer\n",
    "\n",
    "train_ds, val_ds, test_ds, vectorize_layer = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef8c54",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Build BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b521a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_model(vocab_size, embedding_dim):\n",
    "    model = keras.Sequential([\n",
    "        vectorize_layer,\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(32)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ], name=\"BiLSTM_MalwareDetection\")\n",
    "    return model\n",
    "\n",
    "model = build_text_model(CONFIG[\"MAX_TOKENS\"], CONFIG[\"EMBEDDING_DIM\"])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62baa81",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c680101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=CONFIG[\"EPOCHS\"],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training completed in {training_time/60:.2f} minutes ({training_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6197ea7",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d18a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Evaluating model on test set...\")\n",
    "\n",
    "# Get test data\n",
    "test_texts_list = []\n",
    "test_labels_list = []\n",
    "for texts, labels in test_ds:\n",
    "    test_texts_list.extend(texts.numpy())\n",
    "    test_labels_list.extend(labels.numpy())\n",
    "\n",
    "test_texts_array = np.array(test_texts_list)\n",
    "test_labels_array = np.array(test_labels_list)\n",
    "\n",
    "# Predictions\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Metrics\n",
    "accuracy = np.mean(y_pred == test_labels_array)\n",
    "f1 = f1_score(test_labels_array, y_pred)\n",
    "recall = recall_score(test_labels_array, y_pred)\n",
    "precision = precision_score(test_labels_array, y_pred)\n",
    "\n",
    "print(f\"\\nüìà Test Results:\")\n",
    "print(f\"   - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   - F1-Score: {f1:.4f}\")\n",
    "print(f\"   - Recall: {recall:.4f}\")\n",
    "print(f\"   - Precision: {precision:.4f}\")\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(test_labels_array, y_pred, target_names=['Benign', 'Malware']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ac934",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training History\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history plot saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels_array, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malware'],\n",
    "            yticklabels=['Benign', 'Malware'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Binary Classification', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# Add percentages\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        percentage = cm[i, j] / cm[i].sum() * 100\n",
    "        plt.text(j+0.5, i+0.7, f'({percentage:.1f}%)', \n",
    "                ha='center', va='center', fontsize=10, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels_array, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - Binary Classification', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ ROC curve saved! AUC = {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb02432",
   "metadata": {},
   "source": [
    "## üîü Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = f\"output/{CONFIG['MODEL_NAME']}.keras\"\n",
    "model.save(model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'Model': CONFIG['MODEL_NAME'],\n",
    "    'Training Time (min)': f\"{training_time/60:.2f}\",\n",
    "    'Accuracy': f\"{accuracy:.4f}\",\n",
    "    'F1-Score': f\"{f1:.4f}\",\n",
    "    'Recall': f\"{recall:.4f}\",\n",
    "    'Precision': f\"{precision:.4f}\",\n",
    "    'AUC': f\"{roc_auc:.4f}\",\n",
    "    'Date': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('output/evaluation_results.csv', index=False)\n",
    "print(\"‚úÖ Results saved to: output/evaluation_results.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Training completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefc04",
   "metadata": {},
   "source": [
    "## üì• Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Create zip file\n",
    "print(\"üì¶ Creating zip file...\")\n",
    "with zipfile.ZipFile('malware_detection_results.zip', 'w') as zipf:\n",
    "    for root, dirs, filenames in os.walk('output'):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            zipf.write(file_path)\n",
    "\n",
    "print(\"‚úÖ Zip file created!\")\n",
    "print(\"üì• Downloading...\")\n",
    "files.download('malware_detection_results.zip')\n",
    "print(\"‚úÖ Download complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
